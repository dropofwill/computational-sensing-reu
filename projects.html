<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <!-- <meta name="viewport" content="width=device&#45;width, initial&#45;scale=1.0"> -->
  <link rel="stylesheet" href="main.css" media="all">

  <title>REU Computational Sensing at RIT</title>
</head>

<body>

<header class="global-header">
  <div class="wrapper">
    <img class="nsf-logo" src="imgs/nsf-logo.jpg" alt="logo for the National Science Foundation" />

    <div class="header-text">
      <p class="type"><span>The National Science Foundation<br/>
        Rochester Institute of Technology</span></p>
      <h2 class="italic-title">Research Experience for Undergraduates in</h2>
      <h1>Computational Sensing</h1>
    </div>

    <img class="rit-logo" src="imgs/gccis-logo.svg" alt="logo for the National Science Foundation" />
    <img class="rit-logo" src="imgs/cola-logo.svg" alt="logo for the National Science Foundation" />
  </div>
</header>

<nav class="global-nav">
  <div class="wrapper">
    <ul>
      <li><a href="index.html">home</a></li>
      <li><a href="mentors.html">research mentors</a></li>
      <li><a href="workshop.html">workshop facilitators</a></li>
      <li><a href="projects.html">projects</a></li>
      <li><a href="faq.html">faq</a></li>
      <li><a href="activities.html">activities</a></li>
    </ul>
  </div>
</nav>

<section>
  <div class="wrapper">
    <h1>Projects</h1>

    <div class="row">
      <a href="fig3.pdf">
        <img class="col-third" src="imgs/fig3.png" alt="Addtitional information available in the flyer" />
      </a>

      <a href="fig1.pdf">
        <img class="col-third" src="imgs/fig1.png" alt="Addtitional information available in the flyer" />
      </a>
    </div>

    <div class="row">
      <div class="half-col">
        <h2>Project 1: Real-time attention, stress, and cognitive load monitoring</h2>
        <p>
        In recent work, we used a microphone to record speech and a camera to capture facial expressions of individuals engaged in computer-based tasks. The nature of the tasks were manipulated to induce moderate stress. We were later able to fuse both sources of data to reliably predict when the user was stressed. Students involved in this project will build on these ideas and develop techniques for real-time monitoring of user stress, attention, and cognitive load from multisource data towards monitoring in online learning systems.
        </p>
        <p><em>Faculty mentors:</em> Drs. Joe Geigel, Rennie Bailey, Linwei Wang, Cecilia Ovesdotter Alm.</p>
      </div>

      <div class="half-col">
        <h2>Project 2: Macro-level understanding of interpersonal violence</h2>
        <p>Interpersonal violence (IPV) and abuse are prominent problems that impact individuals and macro-level community wellness. Our findings from large social media collections include that beliefs, values, social pressure,  and fears play major roles in keeping people in abusive relationships. Semantic role labeling is a method that can help identify information. Our prior work also showed that such tools are not well tailored to this data. Students will focus on: (1) inventorying and modifying prior semantic role labeling tools to better extract information on IPV from social media data, and (2) identifying quantifiable relations between signals in social media narratives, geospatial information, and demographic data sources.</p>
        <p><em>Faculty mentors:</em> Drs. Chris Homan, Ray Ptucha, Cecilia Ovesdotter Alm.</p>
      </div>
    </div>

    <div class="row">
      <div class="half-col">
        <h2>Project 3: Multimodal interface with adaptive user feedback</h2>
        <p>We will extend techniques to systematically fuse multimodal data, representing experts’ domain knowledge, to improve image understanding. Students will enhance a prototype multimodal interactive user interface with interactive machine learning, to effectively collect and incorporate user feedback to enhance the data fusion results.</p>
        <p><em>Faculty mentors:</em> Drs. Qi Yu and Anne Haake.</p>
      </div>

      <div class="half-col">
        <h2>Project 4: TBA</h2>
      </div>
    </div>

    <div class="row">
      <div class="half-col">
        <h2>Project 5: Visual-Linguistic Alignment and Beyond</h2>
        <p>In statistical machine translation, bitext word alignment is the first step in translating text from one language to another. Alignment algorithms can establish meaningful relationships between observers’ gaze data and their co-collected verbal image descriptions, for image annotation or classification. REU student researchers will (1) with widen the bi-modality alignment framework to new modalities, and (2) automatize transcription with speech recognition and explore alignment quality by factors such as concepts’ concreteness and specificity, domain, and individuals’ background knowledge.</p>
        <p><em>Faculty mentors:</em> Drs. Emily Prud’hommeaux, Cecilia Ovesdotter Alm, and Reynold Bailey.</p>
      </div>
    </div>

  </div>
</section>

<footer class="global-footer">
  <div class="wrapper">
    <h3>Computational Sensing REU <time>(2016-2018)</time></h3>
    <address>
      Rochester Institute of Technology<br/>
      <span>Primary contact:</span> Cecilia Ovesdotter Alm, coagla@rit.edu, (585) 475-7327<br/>
      <span>Secondary contact:</span> Reynold Bailey, rjb@cs.rit.edu, (585) 475-6181
    </address>
  </div>
</footer>

<script src="js/main.js"></script>
</body>
</html>
